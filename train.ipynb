{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68004a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrape import take_the_content, URL_NEG, URL_POS\n",
    "from pre_process import clean_the_content, make_word_token, make_more_clean, make_n_grams\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "import random\n",
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import store_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8054125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 : Scrape the Content from the URL\n",
    "pos = take_the_content(URL = URL_POS)\n",
    "neg = take_the_content(URL = URL_NEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947fc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2 Already Done\n"
     ]
    }
   ],
   "source": [
    "# STEP 2 : PreProcess (Lowering + Sent_tokenize + N-Grams + Lemmatize)\n",
    "dataText = []\n",
    "all_dataText = []\n",
    "\n",
    "for categoryText,categoryName in zip([pos,neg],[\"pos\",\"neg\"]) : \n",
    "    result = clean_the_content(categoryText)\n",
    "    for sentence in result : \n",
    "        raw_word_token = make_n_grams(sentence)\n",
    "        raw_word_token = make_word_token(raw_word_token)\n",
    "        # Clean the stopwords and do lemmatization and n-grams also\n",
    "        clean_word_token = make_more_clean(raw_word_token)\n",
    "        dataText.append([clean_word_token,categoryName])\n",
    "        all_dataText.extend(clean_word_token)\n",
    "print(\"STEP 2 Already Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55915944",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataText = nltk.FreqDist(all_dataText).most_common(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d480e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0a80f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\",\"a\") as f : \n",
    "    for i in all_dataText : \n",
    "        f.write(i[0]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f0074f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3 Already Done\n"
     ]
    }
   ],
   "source": [
    "# STEP 3 : Process the dataText to become the data that can be trained \n",
    "for text_idx in range(len(dataText)) :\n",
    "    result = dict()\n",
    "    data_before = set(dataText[text_idx][0])\n",
    "    for all_key in all_dataText : \n",
    "        result[all_key[0]] = all_key[0] in data_before\n",
    "    dataText[text_idx][0] = result\n",
    "for _ in range(5) : \n",
    "    random.shuffle(dataText)\n",
    "\n",
    "print(\"STEP 3 Already Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8602ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 : Split Data Train and Test\n",
    "data_train = dataText[:int(len(dataText)*0.8)]\n",
    "data_test = dataText[int(len(dataText)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff6fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODE STARTED\n"
     ]
    }
   ],
   "source": [
    "# STEP 5 : Build a Model [FIT DATA INTO MODEL]\n",
    "print(\"TRAINING MODE STARTED\")\n",
    "model_original = nltk.NaiveBayesClassifier.train(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7fdea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear_svc = SklearnClassifier(LinearSVC()).train(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bea666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mnb = SklearnClassifier(MultinomialNB()).train(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ab87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bnb = SklearnClassifier(BernoulliNB()).train(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43ab1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = SklearnClassifier(LogisticRegression()).train(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d8b6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd = SklearnClassifier(SGDClassifier()).train(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901c47f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Original : 0.7524613220815752\n",
      "Accuracy Linear SVC : 0.720112517580872\n",
      "Accuracy MultinomialNB : 0.7487107360525082\n",
      "Accuracy BernoulliNB : 0.757149554617909\n",
      "Accuracy Logist Regr : 0.7374589779653071\n",
      "Accuracy Grad Descent : 0.7257383966244726\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "# STEP 6 : Check the Accuracy of Test Data : \n",
    "accuracy = nltk.classify.accuracy(model_original, data_test)\n",
    "print(f\"Accuracy Original : {accuracy}\")\n",
    "accuracy = nltk.classify.accuracy(model_linear_svc, data_test)\n",
    "print(f\"Accuracy Linear SVC : {accuracy}\")\n",
    "accuracy = nltk.classify.accuracy(model_mnb, data_test)\n",
    "print(f\"Accuracy MultinomialNB : {accuracy}\")\n",
    "accuracy = nltk.classify.accuracy(model_bnb, data_test)\n",
    "print(f\"Accuracy BernoulliNB : {accuracy}\")\n",
    "accuracy = nltk.classify.accuracy(model_lr, data_test)\n",
    "print(f\"Accuracy Logist Regr : {accuracy}\")\n",
    "accuracy = nltk.classify.accuracy(model_sgd, data_test)\n",
    "print(f\"Accuracy Grad Descent : {accuracy}\")\n",
    "\n",
    "# STEP 6 - Post : Check the Answer of First Data Test \n",
    "prediction = model_original.classify(data_test[0][0])\n",
    "print(str(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42826d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Already\n"
     ]
    }
   ],
   "source": [
    "method = store_params.SavePickle(original = model_original, lin_svc = model_linear_svc, mnb = model_mnb, bnb = model_bnb,\n",
    "                                 log_r = model_lr, sgd = model_sgd).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2581f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  boring = True              neg : pos    =     27.8 : 1.0\n",
      "                    warm = True              pos : neg    =     18.2 : 1.0\n",
      "               wonderful = True              pos : neg    =     16.9 : 1.0\n",
      "                 routine = True              neg : pos    =     16.4 : 1.0\n",
      "                  stupid = True              neg : pos    =     15.8 : 1.0\n",
      "                provides = True              pos : neg    =     15.6 : 1.0\n",
      "              engrossing = True              pos : neg    =     14.2 : 1.0\n",
      "                touching = True              pos : neg    =     14.1 : 1.0\n",
      "                    flat = True              neg : pos    =     13.1 : 1.0\n",
      "                   waste = True              neg : pos    =     13.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "model_original.show_most_informative_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReynaldiENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
